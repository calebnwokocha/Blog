<!DOCTYPE html>
<html>
<head>
	<title>Caleb Nwokocha</title>
    <link rel="stylesheet" type="text/css" href="index.css">
</head>
<body>
	<div class="row">
        <div class="column-left">
            <img src="profile.png" alt="Your Name" style="border: 1px solid black;">
	<p><a target="_blank" href="https://www.researchgate.net/publication/371696081_Discipleship_Program">Caleb. (2023). Discipleship Program</a></p>
	<div class="gfm-embed" data-url="https://www.gofundme.com/f/transforming-lives-through-discipleship-program/widget/small/"></div><script defer src="https://www.gofundme.com/static/js/embed.js"></script>
        </div>
        <div class="column-right">
            <div>
                <ul>
			<li><a target="_blank" href="https://www.researchgate.net/publication/371696081_Discipleship_Program">Nwokocha, Caleb. (2023). Discipleship Program. 10.13140/RG.2.2.12039.98725. </a></li>
                    <p></p>
                    <li><a target="_blank" href="https://www.researchgate.net/publication/367162998_Polynomial_Regression_by_Comprehensive_Network">Nwokocha, Caleb. (2023). Polynomial Regression by Comprehensive Network.</a></li>
                        The aim of this paper is to introduce a simple, applicable, and efficient machine learning theory of comprehensive function, comprehensive node, comprehensive layer, 
                        and comprehensive network. A comprehensive network or N-model has multiple layers, each layer has one or multiple nodes, and each node has one 
                        comprehensive function. Section 4 describes N-model optimization method, that an N-model optimizes by optimizing each node, and each node optimizes 
                        its thesis by simply using dynamic programming to update its error mean. A multitasking N-model was applied in linear, nonlinear, and logistic 
                        regression experiments to predict real value y given real value x. The multitasking N-model passed 20 test after learning 8 examples.
                    <p></p>
                    <li><a target="_blank" href="https://www.researchgate.net/publication/363488132_Dynamic_Programming_Arithmetic_Geometric_Harmonic_and_Power_Means">Nwokocha, Caleb. (2022). Dynamic Programming: Arithmetic, Geometric, Harmonic, and Power Means. 10.13140/RG.2.2.36168.19200/4.</a></li>
                    Arithmetic, Geometric, and Harmonic means are the well-known Pythagorean means [1, 2, 4, 3]. Power mean, also known as H√∂lder mean, is a generalized mean for the Pythagorean means [5]. 
                    Formulas of these means have been used to derive brute-force algorithms that run at polynomial time and space ùëÇ(ùëõ), but these brute-force algorithms 
                    cost more time and space when compared to their dynamic counterpart. In this paper, I derive dynamic algorithms using technique of dynamic programming 
                    for computing Pythagorean and generalized power means. Derivations of the dynamic algorithms are written in the sections 2-5, and a weblink to Java 
                    implementation of the dynamic algorithms is provided at the end of section 2. Derivations of the dynamic and brute-force mean algorithms make use of 
                    formulas found in statistics resources like Moore et al, 1998; Stan, 2009; and Chou, 1969; although the dynamic mean algorithms have elements of 
                    dynamic programming. I show that dynamic mean algorithms require only constant time and space ùëÇ(1) to compute the mean of a variable. These dynamic 
                    algorithms are less costly than the brute-force algorithms because the latter require ùëÇ(ùëõ) time and space. Implementation of the dynamic algorithms 
                    may be found in applications that process instant mathematical mean of very large data with respect to the time each datum is acquired. An example 
                    of a simple application is provided in the introduction section, where Bob calculates the mean number of oranges that he receives each day from Alice.
                    <p></p>
                    <li><a target="_blank" href="https://www.researchgate.net/publication/362410471_Functional_Rule_Extraction_Method_for_Artificial_Neural_Networks">Nwokocha, Caleb. (2022). Functional Rule Extraction Method for Artificial Neural Networks. 10.48550/arXiv.2208.00335.</a></li>
                    The idea I propose in this paper is a method that is based on comprehensive functions for directed and undirected rule extraction from artificial neural network operations. Firstly, I defined comprehensive functions, then constructed a
                     comprehensive multilayer network (denoted as Œù). Each activation function of Œù is parametrized to a comprehensive function. Following Œù construction, I extracted rules from the network by observing that the network output depends on probabilities of composite 
                     functions that are comprehensive functions. This functional rule extraction method applies to the perceptron and multilayer neural network. For any Œù-model that is trained to predict some outcome given some event, that model behaviour can be expressed ‚Äì using the 
                     functional rule extraction method ‚Äì as a formal rule or informal rule obeyed by the network to predict that outcome. As example, figure 1 consist of a comprehensive physics function that is parameter for one of the network hidden activation functions. Using the 
                     functional rule extraction method, I deduced that the comprehensive multilayer network prediction depends on probability of that physics function and probabilities of other composite comprehensive functions in Œù. Additionally, functional rule extraction method 
                     can aid in applied settings for generation of equations of learned phenomena. This generation can be achieved by first training an Œù-model toward predicting outcome of a phenomenon, then extracting the rules and assuming that probability values of the network 
                     comprehensive functions are constants. Finally, to simplify the generated equation, comprehensive functions with probability p = 0 can be omitted.
		    <p></p>
		    <li><a target="_blank" href="https://www.researchgate.net/profile/Caleb-Nwokocha/research">ResearchGate</a></li>
                </ul>
            </div>
        </div>
    </div>
    <footer>
       	<p>Send emails to <a href="mailto:calebnwokocha@gmail.com" id="email">calebnwokocha@gmail.com</a></p>
    </footer>
</body>
</html>

